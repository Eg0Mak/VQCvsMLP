<div align="center">

# Quantum vs Classical: A Comparative Study of Variational Quantum Classifiers and Neural Networks on Synthetic Data

## Квант против классики: Сравнительное исследование вариационных квантовых классификаторов и нейросетей на синтетических данных

</div>


## О проекте

Проект исследует производительность **Variational Quantum Classifier (VQC)**, его гибридной версии **VQC_hybrid** и классической нейросети **MLP** на синтетических датасетах `Circles` и `Moons`.
Основная цель — понять, в каких задачах квантовая модель может быть конкурентоспособной с классической нейросетью и как архитектура и параметры модели (например, число кубитов) влияют на результаты.

### Цели

1. Сравнить точность классификации MLP и квантовых моделей на простых синтетических датасетах.
2. Исследовать влияние архитектуры VQC (чистый квантовый слой vs гибридный) на эффективность.
3. Проверить, как число кубитов (`n_qubits`) влияет на выражаемость модели и качество классификации.
4. Визуализировать зависимость границы решений и кривых AUC для разных моделей.

### Задачи

* Обучить три модели на `Circles` и `Moons`.
* Посчитать метрики: **Accuracy** и **ROC AUC**.
* Построить графики: Confusion Matrix, ROC-кривая, Training Plot, Decision Boundary.
* Сформулировать математическое обоснование поведения моделей и интерпретировать зависимость метрик от архитектуры и числа кубитов.

---

## Метрики

* **Accuracy**:

$$
\mathrm{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

* **ROC AUC**:

$$
\mathrm{AUC} = \int_0^1 TPR(FPR), d(FPR), \quad
TPR = \frac{TP}{TP + FN}, \quad
FPR = \frac{FP}{FP + TN}
$$

ROC AUC интерпретируется как вероятность того, что случайный положительный объект получит больший прогнозный скор, чем случайный отрицательный:

$$
\mathrm{AUC} = \mathbb{P}(s(x^+) > s(x^-))
$$

---

## Датасет Circles

* Радиальная структура:

$$
x_1^2 + x_2^2 = r^2
$$

* **Лучшие результаты:** `VQC_hybrid` (ROC AUC ≈ 0.711, Accuracy ≈ 0.653)
* MLP почти случайная (ROC AUC ≈ 0.537)

### Математическое обоснование

В VQC_hybrid квантовый слой выполняет **feature mapping**:

$$
x \mapsto U(x) |0\rangle
$$

и вычисляет ожидаемое значение наблюдаемой:

$$
\phi(x) = \langle 0 | U^\dagger(x) O U(x) | 0 \rangle
$$

где (U(x)) — параметризованная квантовая схема (AngleEmbedding + Ansatz), (O) — измеряемый оператор.
Квантовое ядро:

$$
K(x_i, x_j) = |\langle \psi(x_i) | \psi(x_j) \rangle|^2
$$

позволяет моделировать **сложные нелинейные зависимости между объектами**, что делает VQC_hybrid более выразительной для радиально-симметричных классов.

#### Что такое Ansatz:

**Описание:**
Ansatz — это параметризованная квантовая схема, которая формирует вариационное квантовое состояние и позволяет модели учиться сложным зависимостям в данных. В `VQC_hybrid` используется `StronglyEntanglingLayers`, обеспечивающий как индивидуальные вращения кубитов, так и их перепутывание. Этот слой отвечает за создание выразительных квантовых признаков, которые затем передаются в классический слой для классификации, повышая способность модели различать сложные закономерности в данных.

**Локальные вращения кубитов:**
Каждый кубит (i) подвергается последовательным вращениям по осям X, Y и Z:
[
R_i(\theta_i) = R_X(\theta_i^x) R_Y(\theta_i^y) R_Z(\theta_i^z)
]
Эти вращения позволяют изменять состояние кубита на сфере Блоха произвольно, создавая разнообразные квантовые суперпозиции.

**Энтанглирование:**
После локальных вращений кубиты перепутываются многокубитными вентилями, формируя корреляции между ними. Это критично для моделирования сложных зависимостей и нелинейных отношений в данных.

**Слои Ansatz:**
Схема повторяется в (L) слоях, формируя итоговую трансформацию:
[
U(\Theta) = \prod_{l=1}^{L} (\text{EntangleLayer} \cdot \bigotimes_i R_i(\theta_i^{(l)}))
]
где (\Theta) — набор всех параметров, которые оптимизируются в процессе обучения.

**Кодирование входных данных и выход:**
Входные данные (\mathbf{x}) кодируются через AngleEmbedding:
[
|\psi_0\rangle = \bigotimes_i R_Y(x_i)|0\rangle
]
Ansatz преобразует это состояние в (|\psi(\Theta)\rangle = U(\Theta)|\psi_0\rangle), после чего измерения (\langle Z_i \rangle) служат признаками для классического линейного слоя с сигмоидой.

Квантовый слой с Ansatz создаёт выразительные и коррелированные признаки данных, которые усиливают классическую часть модели, обеспечивая гибридное квантово-классическое обучение и позволяя эффективно распознавать сложные и нелинейные зависимости в данных.

Вот как можно аккуратно встроить объяснение пунктов 2 и 3 в твой раздел, логически продолжив математическое обоснование.

---

#### Почему VQC_hybrid лучше MLP

1. **Нелинейное расширение пространства признаков**

   В исходном пространстве (\mathbb{R}^2) классы не являются линейно разделимыми.
   Квантовый слой выполняет отображение:

   $$
   \mathbb{R}^2 \rightarrow \mathcal{H}, \quad \dim(\mathcal{H}) = 2^{n_{qubits}}
   $$

   Даже при (n_{qubits}=2) пространство признаков становится существенно богаче.
   Радиальная зависимость (x_1^2 + x_2^2) может быть представлена через тригонометрические комбинации углов поворота кубитов.

   В результате линейный классический слой после квантового блока фактически работает в уже **нелинейно преобразованном пространстве**, что даёт преимущество над небольшой MLP.

2. **Энтанглирование как источник коррелированных признаков**

   Благодаря слоям перепутывания (entanglement) признаки становятся зависимыми друг от друга.
   Это позволяет квантовой схеме моделировать взаимодействия вида:

   $$
   f(x_1, x_2) \neq f_1(x_1) + f_2(x_2)
   $$

   Для задачи Circles именно такие совместные нелинейные зависимости критичны, поскольку принадлежность к классу определяется радиусом, а не линейной комбинацией координат.

   Простая MLP с малым числом нейронов может не выучить эту структуру, тогда как квантовый feature map изначально задаёт нелинейную геометрию пространства.

---

#### Почему результаты гибридной модели всё ещё низкие

Несмотря на архитектурное преимущество, метрики остаются умеренными. Это объясняется несколькими факторами.

1. **Высокий уровень шума**

   При параметре `noise = 0.3` классы существенно перекрываются.
   Это означает, что существует область, где:

   $$
   P(y=1 \mid x) \approx 0.5
   $$

   Даже идеальный классификатор в такой зоне не сможет достичь высокой Accuracy.
   Шум ограничивает верхнюю границу качества.

2. **Ограниченная выразительность схемы**

   При фиксированном числе кубитов и слоёв Ansatz множество реализуемых функций ограничено:

   $$
   \mathcal{F}*{VQC} \subsetneq \mathcal{F}*{all}
   $$

   Если глубина схемы мала, модель не способна точно аппроксимировать сложную и шумную границу разделения.

3. **Ограниченность классической части**

   После квантового блока используется один линейный слой:

   $$
   \hat{y} = \sigma(W \phi(x) + b)
   $$

   Если квантовые признаки частично перекрываются для разных классов, одного линейного преобразования недостаточно для точного разделения.

4. **Сложность оптимизации**

   При увеличении числа кубитов и параметров градиенты могут уменьшаться (эффект barren plateau), что ухудшает поиск глобального минимума и ограничивает достижимое качество.

---

Таким образом:

* VQC_hybrid превосходит MLP, потому что квантовый слой создаёт более подходящее нелинейное представление для радиальной структуры
* Однако архитектурные ограничения, шум в данных и сложности оптимизации не позволяют модели достичь высокой AUC
* Рост числа кубитов без увеличения глубины или усложнения классической части не приводит к заметному улучшению


### Влияние числа кубитов

Число кубитов расширяет размерность пространства признаков:

$$
n_{qubits} \uparrow \implies \dim(\mathcal{H}) = 2^{n_{qubits}} \uparrow
$$

Однако для задачи Circles:

$$
\frac{\partial \mathrm{AUC}}{\partial n_{qubits}} \approx 0
$$

то есть **2 кубитов уже достаточно**, дальнейший рост числа кубитов не даёт значимого улучшения.

---

## Датасет Moons

* Гладкая нелинейная граница:

$$
f(x) = \sigma\big(W_2 , \sigma(W_1 x + b_1) + b_2\big)
$$

* **Лучшие результаты:** MLP (ROC AUC ≈ 0.972, Accuracy ≈ 0.915)
* VQC_hybrid хуже (AUC ≈ 0.884), VQC уступает ещё сильнее

### Математическое объяснение

MLP аппроксимирует гладкую функцию разделения классов, используя последовательность линейных и нелинейных преобразований. Квантовые модели с ограниченным числом кубитов и слоёв Ansatz имеют меньшую способность к гладкой аппроксимации и могут сталкиваться с:

* **Barren plateau** — затухание градиентов при увеличении числа кубитов
* **Ограниченная выразительность** - ограниченная выразительность означает, что при фиксированном числе кубитов и слоёв квантовая схема может реализовать только ограниченное множество форм разделяющей границы. На задаче Circles её нелинейное feature mapping помогает лучше разделять радиальную структуру данных. Однако на Moons граница более плавная и требует гибкой аппроксимации, и здесь MLP оказывается мощнее: она может точнее «подогнать» форму разделяющей поверхности, тогда как VQC ограничена своей архитектурой и потому уступает по AUC.

### Влияние числа кубитов

Для Moons рост числа кубитов:

$$
n_{qubits}: 2 \to 4 \to 8 \implies \text{Accuracy снижается у VQC}
$$

Это демонстрирует, что **увеличение размерности без дополнительного классического слоя** не всегда улучшает качество.

---

## Визуализация результатов

Для каждой задачи показаны **только лучшие модели**:

* Circles → `VQC_hybrid`
* Moons → `MLP`

### Распределение данных

![Данные Circles и Moons](graphics/data.png)

### Circles — VQC_hybrid

**Confusion Matrix**  

![Confusion Matrix Circles](graphics/matrix_circles.png)

**ROC Curve**  

![ROC Curve Circles](graphics/roc_auc_circles.png)

**Training Plot**  

![Training Plot Circles](graphics/training_circles.png)

**Decision Boundary**  

![Decision Boundary Circles](graphics/boundary_circles.png)

---

### Moons — MLP

**Confusion Matrix**  

![Confusion Matrix Moons](graphics/matrix_moons.png)

**ROC Curve**  

![ROC Curve Moons](graphics/roc_auc_moons.png)

**Training Plot**  

![Training Plot Moons](graphics/training_moons.png)

**Decision Boundary**  

![Decision Boundary Moons](graphics/boundary_moons.png)


Остальные модели отображаются в таблицах метрик для полного сравнения

---

## Таблица точности моделей

| Model      | Dataset | n_qubits | Accuracy | ROC AUC  |
| ---------- | ------- | -------- | -------- | -------- |
| VQC_hybrid | Circles | 2.0      | 0.653333 | 0.711292 |
| VQC_hybrid | Circles | 4.0      | 0.653333 | 0.711261 |
| VQC_hybrid | Circles | 8.0      | 0.653333 | 0.711279 |
| MLP        | Circles | -        | 0.647333 | 0.536823 |
| VQC        | Circles | 2.0      | 0.592667 | 0.707922 |
| VQC        | Circles | 4.0      | 0.634000 | 0.707733 |
| VQC        | Circles | 8.0      | 0.635333 | 0.707806 |
| MLP        | Moons   | -        | 0.914667 | 0.972028 |
| VQC_hybrid | Moons   | 2.0      | 0.882667 | 0.932067 |
| VQC_hybrid | Moons   | 4.0      | 0.884000 | 0.932121 |
| VQC_hybrid | Moons   | 8.0      | 0.884000 | 0.932137 |
| VQC        | Moons   | 2.0      | 0.844667 | 0.921283 |
| VQC        | Moons   | 4.0      | 0.777333 | 0.875150 |
| VQC        | Moons   | 8.0      | 0.778667 | 0.875140 |

---

## Выводы

1. **Квантовые модели лучше справляются с радиально-симметричными данными (Circles)** благодаря нелинейному feature mapping.
2. **Классическая MLP превосходит квантовые модели на гладких задачах (Moons)**, демонстрируя более высокую AUC и стабильность обучения.
3. **Гибридная архитектура (VQC_hybrid)** эффективно использует квантовый слой как feature extractor, что повышает выразительность и точность.
4. **Число кубитов влияет на выразительность**, но прирост метрик ограничен, особенно без классического слоя.
5. Результаты подчёркивают **структурно-зависимый характер квантового преимущества** — оно проявляется на специфических геометриях данных.

---

## Технологии

* [PennyLane](https://github.com/PennyLaneAI/pennylane) — квантовые модели
* PyTorch — классические сети
* Scikit-learn — датасеты и метрики
* Matplotlib / Seaborn — визуализация

## Как запустить

* Весь эксперимент находится в Jupyter Notebook: `notebooks/vqc_vs_mlp.ipynb`
* Установите необходимые зависимости
* Откройте ноутбук и выполните все ячейки последовательно