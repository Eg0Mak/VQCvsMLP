<center>

# Quantum vs Classical: A Comparative Study of Variational Quantum Classifiers and Neural Networks on Synthetic Data

## Квант против классики: Сравнительное исследование вариационных квантовых классификаторов и нейросетей на синтетических данных

</center>


## О проекте

Проект исследует производительность **Variational Quantum Classifier (VQC)**, его гибридной версии **VQC_hybrid** и классической нейросети **MLP** на синтетических датасетах `Circles` и `Moons`.
Основная цель — понять, в каких задачах квантовая модель может быть конкурентоспособной с классической нейросетью и как архитектура и параметры модели (например, число кубитов) влияют на результаты.

### Цели

1. Сравнить точность классификации MLP и квантовых моделей на простых синтетических датасетах.
2. Исследовать влияние архитектуры VQC (чистый квантовый слой vs гибридный) на эффективность.
3. Проверить, как число кубитов (`n_qubits`) влияет на выражаемость модели и качество классификации.
4. Визуализировать зависимость границы решений и кривых AUC для разных моделей.

### Задачи

* Обучить три модели на `Circles` и `Moons`.
* Посчитать метрики: **Accuracy** и **ROC AUC**.
* Построить графики: Confusion Matrix, ROC-кривая, Training Plot, Decision Boundary.
* Сформулировать математическое обоснование поведения моделей и интерпретировать зависимость метрик от архитектуры и числа кубитов.

---

## Метрики

* **Accuracy**:

$$
\mathrm{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
$$

* **ROC AUC**:

$$
\mathrm{AUC} = \int_0^1 TPR(FPR), d(FPR), \quad
TPR = \frac{TP}{TP + FN}, \quad
FPR = \frac{FP}{FP + TN}
$$

ROC AUC интерпретируется как вероятность того, что случайный положительный объект получит больший прогнозный скор, чем случайный отрицательный:

$$
\mathrm{AUC} = \mathbb{P}(s(x^+) > s(x^-))
$$

---

## Датасет Circles

* Радиальная структура:

$$
x_1^2 + x_2^2 = r^2
$$

* **Лучшие результаты:** `VQC_hybrid` (ROC AUC ≈ 0.711, Accuracy ≈ 0.653)
* MLP почти случайная (ROC AUC ≈ 0.537)

### Математическое обоснование

В VQC_hybrid квантовый слой выполняет **feature mapping**:

$$
x \mapsto U(x) |0\rangle
$$

и вычисляет ожидаемое значение наблюдаемой:

$$
\phi(x) = \langle 0 | U^\dagger(x) O U(x) | 0 \rangle
$$

где (U(x)) — параметризованная квантовая схема (AngleEmbedding + Ansatz), (O) — измеряемый оператор.
Квантовое ядро:

$$
K(x_i, x_j) = |\langle \psi(x_i) | \psi(x_j) \rangle|^2
$$

позволяет моделировать **сложные нелинейные зависимости между объектами**, что делает VQC_hybrid более выразительной для радиально-симметричных классов.

### Влияние числа кубитов

Число кубитов расширяет размерность пространства признаков:

$$
n_{qubits} \uparrow \implies \dim(\mathcal{H}) = 2^{n_{qubits}} \uparrow
$$

Однако для задачи Circles:

$$
\frac{\partial \mathrm{AUC}}{\partial n_{qubits}} \approx 0
$$

то есть **2 кубитов уже достаточно**, дальнейший рост числа кубитов не даёт значимого улучшения.

---

## Датасет Moons

* Гладкая нелинейная граница:

$$
f(x) = \sigma\big(W_2 , \sigma(W_1 x + b_1) + b_2\big)
$$

* **Лучшие результаты:** MLP (ROC AUC ≈ 0.972, Accuracy ≈ 0.915)
* VQC_hybrid хуже (AUC ≈ 0.884), VQC уступает ещё сильнее

### Математическое объяснение

MLP аппроксимирует гладкую функцию разделения классов, используя последовательность линейных и нелинейных преобразований. Квантовые модели с ограниченным числом кубитов и слоёв Ansatz имеют меньшую способность к гладкой аппроксимации и могут сталкиваться с:

* **Barren plateau** — затухание градиентов при увеличении числа кубитов
* **Ограниченная выразительность** — параметризованные схемы не способны точно воспроизвести сложную кривую

### Влияние числа кубитов

Для Moons рост числа кубитов:

$$
n_{qubits}: 2 \to 4 \to 8 \implies \text{Accuracy снижается у VQC}
$$

Это демонстрирует, что **увеличение размерности без дополнительного классического слоя** не всегда улучшает качество.

---

## Визуализация результатов

Для каждой задачи показаны **только лучшие модели**:

* Circles → `VQC_hybrid`
* Moons → `MLP`

### Распределение данных

![Данные Circles и Moons](graphics/data.png)

### Circles — VQC_hybrid

**Confusion Matrix**  

![Confusion Matrix Circles](graphics/matrix_circles.png)

**ROC Curve**  

![ROC Curve Circles](graphics/roc_auc_circles.png)

**Training Plot**  

![Training Plot Circles](graphics/training_circles.png)

**Decision Boundary**  

![Decision Boundary Circles](graphics/boundary_circles.png)

---

### Moons — MLP

**Confusion Matrix**  

![Confusion Matrix Moons](graphics/matrix_moons.png)

**ROC Curve**  

![ROC Curve Moons](graphics/roc_auc_moons.png)

**Training Plot**  

![Training Plot Moons](graphics/training_moons.png)

**Decision Boundary**  

![Decision Boundary Moons](graphics/boundary_moons.png)


Остальные модели отображаются в таблицах метрик для полного сравнения

---

## Таблица точности моделей

| Model      | Dataset | n_qubits | Accuracy | ROC AUC  |
| ---------- | ------- | -------- | -------- | -------- |
| VQC_hybrid | Circles | 2.0      | 0.653333 | 0.711292 |
| VQC_hybrid | Circles | 4.0      | 0.653333 | 0.711261 |
| VQC_hybrid | Circles | 8.0      | 0.653333 | 0.711279 |
| MLP        | Circles | -        | 0.647333 | 0.536823 |
| VQC        | Circles | 2.0      | 0.592667 | 0.707922 |
| VQC        | Circles | 4.0      | 0.634000 | 0.707733 |
| VQC        | Circles | 8.0      | 0.635333 | 0.707806 |
| MLP        | Moons   | -        | 0.914667 | 0.972028 |
| VQC_hybrid | Moons   | 2.0      | 0.882667 | 0.932067 |
| VQC_hybrid | Moons   | 4.0      | 0.884000 | 0.932121 |
| VQC_hybrid | Moons   | 8.0      | 0.884000 | 0.932137 |
| VQC        | Moons   | 2.0      | 0.844667 | 0.921283 |
| VQC        | Moons   | 4.0      | 0.777333 | 0.875150 |
| VQC        | Moons   | 8.0      | 0.778667 | 0.875140 |

---

## Выводы

1. **Квантовые модели лучше справляются с радиально-симметричными данными (Circles)** благодаря нелинейному feature mapping.
2. **Классическая MLP превосходит квантовые модели на гладких задачах (Moons)**, демонстрируя более высокую AUC и стабильность обучения.
3. **Гибридная архитектура (VQC_hybrid)** эффективно использует квантовый слой как feature extractor, что повышает выразительность и точность.
4. **Число кубитов влияет на выразительность**, но прирост метрик ограничен, особенно без классического слоя.
5. Результаты подчёркивают **структурно-зависимый характер квантового преимущества** — оно проявляется на специфических геометриях данных.

---

## Технологии

* [PennyLane](https://github.com/PennyLaneAI/pennylane) — квантовые модели
* PyTorch — классические сети
* Scikit-learn — датасеты и метрики
* Matplotlib / Seaborn — визуализация

## Как запустить

* Весь эксперимент находится в Jupyter Notebook: `notebooks/vqc_vs_mlp.ipynb`
* Установите необходимые зависимости
* Откройте ноутбук и выполните все ячейки последовательно